{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with stat_Master file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cluster_finder\n",
    "import numpy as np\n",
    "from cluster_plotter import ClusterPlotter\n",
    "\n",
    "testfile = r\"input\\stat_Master_02_geo_s1.crs\"\n",
    "data = cluster_finder.prepare_data_for_clustering(testfile)  # data is a named tuple (inc, raan, ecc)\n",
    "\n",
    "bandwidths = np.arange(0.2, 0.5, 0.04)\n",
    "best_bandwidth, scores = cluster_finder.find_best_bandwidth(data, bandwidths)\n",
    "cluster_finder.plot_bandwidth_against_score(bandwidths, scores)\n",
    "\n",
    "cluster_data = cluster_finder.find_clusters_mean_shift_clustering(data, best_bandwidth)\n",
    "data = cluster_data.data \n",
    "labels = cluster_data.labels\n",
    "cluster_centers = cluster_data.cluster_centers\n",
    "\n",
    "print(\"Cluster Centers:\", cluster_centers)\n",
    "\n",
    "# Assuming ClusterPlotter is defined somewhere else\n",
    "plotter = ClusterPlotter(data, labels, cluster_centers)\n",
    "plotter.clusters_3d_plot(\"3D Cluster Visualization\")\n",
    "plotter.clusters_2d_plot(\"2D Cluster Visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002 geo\n",
      "Bandwidth: 0.2, Silhouette Score: 0.3855328177458831\n",
      "Bandwidth: 0.25, Silhouette Score: 0.5130814660965503\n",
      "Bandwidth: 0.3, Silhouette Score: 0.5417155015594003\n",
      "Bandwidth: 0.35, Silhouette Score: 0.5318661687895904\n",
      "Bandwidth: 0.4, Silhouette Score: 0.2716892245928157\n",
      "Best bandwidth: 0.3 with Silhouette Score: 0.5417155015594003\n"
     ]
    }
   ],
   "source": [
    "import cluster_finder\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from cluster_plotter import ClusterPlotter  # Assuming your plotting module is saved as cluster_plotter.py\n",
    "\n",
    "seed = 1\n",
    "years = [\"2002\", \"2003\", \"2004\", \"2005\"]\n",
    "orbit_types = [\"geo\", \"gto\", \"fol\"]\n",
    "\n",
    "cluster_evolution = {}\n",
    "updated_10cm_cluster_evolution = {}\n",
    "\n",
    "cluster_centers_5mm_dict = {}\n",
    "cluster_centers_10cm_dict = {}\n",
    "matches_dict = {}  # Store matched clusters\n",
    "\n",
    "bandwidths = [0.2, 0.25, 0.3, 0.35, 0.4]\n",
    "for orbit_type in orbit_types: \n",
    "    for year in years: \n",
    "        print(year, orbit_type)\n",
    "        file_5mm, file_10cm = cluster_finder.get_files_for_cluster_evolution(year, orbit_type, seed, \"input\")\n",
    "        clusters_5mm, clusters_10cm, clusters_5mm_array, clusters_10cm_array = cluster_finder.find_clusters_for_one_year(file_5mm, file_10cm, bandwidths)\n",
    "                \n",
    "        # Add clusters to the evolution dictionary\n",
    "        cluster_evolution[(year, orbit_type, seed)] = {\n",
    "            \"clusters_5mm\": clusters_5mm,\n",
    "            \"clusters_10cm\": clusters_10cm\n",
    "        }\n",
    "        \n",
    "        # Compare clusters and store updated data\n",
    "        updated_10cm_cluster_data = cluster_finder.cluster_comparison(clusters_5mm_array, clusters_10cm_array)\n",
    "        updated_10cm_cluster_evolution[(year, orbit_type, seed)] = updated_10cm_cluster_data\n",
    "\n",
    "        # Get cluster centers\n",
    "        clusters_center_5mm = clusters_5mm.cluster_centers\n",
    "        clusters_center_10cm = clusters_10cm.cluster_centers\n",
    "\n",
    "        # Match clusters using Hungarian algorithm\n",
    "        matches, unmatched_10cm, unmatched_5mm = cluster_finder.match_clusters(clusters_center_10cm, clusters_center_5mm)\n",
    "        matches_dict[(year, orbit_type, seed)] = matches\n",
    "\n",
    "        # Store cluster centers for plotting\n",
    "        cluster_centers_5mm_dict[(year, orbit_type, seed)] = clusters_center_5mm\n",
    "        cluster_centers_10cm_dict[(year, orbit_type, seed)] = clusters_center_10cm\n",
    "\n",
    "        # Visualize matched clusters\n",
    "        plotter_5mm = ClusterPlotter(clusters_5mm.data, clusters_5mm.labels, clusters_5mm.cluster_centers)\n",
    "        plotter_5mm.combined_clusters_2d_plot(\n",
    "            clusters_10cm.data, clusters_10cm.labels, clusters_center_10cm,\n",
    "            title=f\"Matched Clusters in {year} ({orbit_type})\"\n",
    "        )\n",
    "\n",
    "cluster_finder.plot_cluster_center_evolution(cluster_centers_5mm_dict, cluster_centers_10cm_dict)\n",
    "cluster_finder.plot_cluster_center_evolution_2d(cluster_centers_5mm_dict, cluster_centers_10cm_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cluster_finder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from cluster_plotter import ClusterPlotter\n",
    "\n",
    "data_5mm = r\"input\\small_Master_02_geo_s1.crs\" #crossing data for objects larger than 5mm\n",
    "data_5mm = cluster_finder.prepare_data_for_clustering(data_5mm)\n",
    "\n",
    "bandwidths =  [0.3] #np.arange(0.2, 0.5, 0.05)#bandwidths to find\n",
    "best_bandwidth_5mm, scores_5mm = cluster_finder.find_best_bandwidth(data_5mm, bandwidths)\n",
    "clusters_5mm = cluster_finder.find_clusters_mean_shift_clustering(data_5mm, best_bandwidth_5mm)\n",
    "\n",
    "cluster_data_5mm = clusters_5mm.data\n",
    "labels_5mm = clusters_5mm.labels\n",
    "cluster_centers_5mm = clusters_5mm.cluster_centers\n",
    "\n",
    "data_10cm = r\"input\\stat_Master_02_geo_s1.crs\" #crossing data for objects larger than 10cm\n",
    "data_10cm = cluster_finder.prepare_data_for_clustering(data_10cm)\n",
    "\n",
    "best_bandwidth_10cm, scores_10cm = cluster_finder.find_best_bandwidth(data_10cm, bandwidths)\n",
    "clusters_10cm = cluster_finder.find_clusters_mean_shift_clustering(data_10cm, best_bandwidth_10cm)\n",
    "\n",
    "cluster_data_10cm = clusters_10cm.data\n",
    "labels_10cm = clusters_10cm.labels\n",
    "cluster_centers_10cm = clusters_10cm.cluster_centers\n",
    "\n",
    "#store clusters for both datasets in numpy array\n",
    "clusters_5mm = cluster_finder.store_clusters(cluster_data_5mm, labels_5mm)\n",
    "clusters_10cm = cluster_finder.store_clusters(cluster_data_10cm, labels_10cm)\n",
    "#print the number of clusters for both datasets\n",
    "print(f\"5mm dataset clusters: {len(clusters_5mm)}\")\n",
    "print(f\"10cm dataset clusters: {len(clusters_10cm)}\")\n",
    "\n",
    "#convert clusters to array\n",
    "clusters_5mm_array = cluster_finder.convert_clusters_to_array(clusters_5mm)\n",
    "clusters_10cm_array = cluster_finder.convert_clusters_to_array(clusters_10cm)\n",
    "\n",
    "updated_10cm_cluster_data = []\n",
    "total_10cm_elements = sum([len(elements) for elements in clusters_10cm.values()])\n",
    "total_5mm_elements = sum([len(elements) for elements in clusters_5mm.values()])\n",
    "print(f\"Total 10cm Cluster Elements: {total_10cm_elements}\")\n",
    "print(f\"Total 5mm Cluster Elements: {total_5mm_elements}\")\n",
    "\n",
    "count = 0 #count number of matches\n",
    "\n",
    "data_10cm = clusters_10cm_array[:, 1:]  #only the inc, raan, ecc, cluster label is removed\n",
    "data_5mm = clusters_5mm_array[:, 1:]\n",
    "\n",
    "print(len(data_10cm[0]))\n",
    "print(len(data_5mm[0]))\n",
    "for row_index, row_10cm in enumerate(data_10cm):  # Iterate over rows in the 10cm dataset\n",
    "    matched = False\n",
    "    matches = np.all(np.isclose(data_5mm, row_10cm, atol=1e-20), axis=1) #tolerance to 10e-20 is the way to go\n",
    "    \n",
    "    if np.any(matches):\n",
    "        matched_indices = np.where(matches)[0]\n",
    "        for idx in matched_indices:\n",
    "            matched_row = clusters_5mm_array[idx]\n",
    "            updated_10cm_cluster_data.append(\n",
    "                [clusters_10cm_array[row_index, 0]] + list(row_10cm) + [matched_row[0]]\n",
    "            )\n",
    "            matched = True\n",
    "            break  # Stop searching once the first match is found\n",
    "\n",
    "    if not matched:\n",
    "        count += 1\n",
    "\n",
    "updated_10cm_cluster_data = np.array(updated_10cm_cluster_data)\n",
    "\n",
    "print(\"Updated 10cm Cluster Data with 5mm Cluster Labels:\")\n",
    "print(updated_10cm_cluster_data)\n",
    "print(f\"Number of unmatched 10cm elements: {count}\")#should be zero\n",
    "\n",
    "first_column = updated_10cm_cluster_data[:, 0]  # First column: 10cm cluster labels\n",
    "last_column = updated_10cm_cluster_data[:, -1]  # Last column: 5mm cluster labels\n",
    "mismatches = first_column != last_column\n",
    "num_mismatches = np.sum(mismatches)\n",
    "print(f\"Number of rows where the first and last columns do not match: {num_mismatches}\")\n",
    "print(f\"Total number of rows: {updated_10cm_cluster_data.shape[0]}\")\n",
    "print(f\"Mismatch percentage: {num_mismatches / updated_10cm_cluster_data.shape[0] * 100:.2f}%\")\n",
    "\n",
    "\"\"\"# Plotting for the 5mm dataset\n",
    "plotter_5mm = ClusterPlotter(cluster_data_5mm, labels_5mm, cluster_centers_5mm)\n",
    "plotter_5mm.clusters_3d_plot(\"3D Cluster Visualization for 5mm Data\")\n",
    "plotter_5mm.clusters_2d_plot(\"2D Cluster Visualization for 5mm Data\")\n",
    "\n",
    "# Plotting for the 10cm dataset\n",
    "plotter_10cm = ClusterPlotter(cluster_data_10cm, labels_10cm, cluster_centers_10cm)\n",
    "plotter_10cm.clusters_3d_plot(\"3D Cluster Visualization for 10cm Data\")\n",
    "plotter_10cm.clusters_2d_plot(\"2D Cluster Visualization for 10cm Data\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter_5mm = ClusterPlotter(data_5mm, labels_5mm, cluster_centers_5mm)\n",
    "\n",
    "# Call combined 2D plot\n",
    "plotter_5mm.combined_clusters_2d_plot(data_10cm, labels_10cm, cluster_centers_10cm,\n",
    "                                      title=\"Combined 2D Clusters for 5mm and 10cm\")\n",
    "\n",
    "# Call combined 3D plot\n",
    "plotter_5mm.combined_clusters_3d_plot(data_10cm, labels_10cm, cluster_centers_10cm,\n",
    "                                      title=\"Combined 3D Clusters for 5mm and 10cm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof of Concept, it seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#https://www.geeksforgeeks.org/ml-mean-shift-clustering/\n",
    "\n",
    "#generate fake data with three main clusters\n",
    "cluster_centers = [\n",
    "    [5, 90, 0.2],    \n",
    "    [15, 180, 0.7],  \n",
    "    [20, 300, 0.4]   \n",
    "]\n",
    "cluster_std = [3, 0.7, 1]  # standard deviation for each feature\n",
    "\n",
    "data, _ = make_blobs(n_samples=1000, centers=cluster_centers, cluster_std=cluster_std, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(data)\n",
    "\n",
    "# Apply Mean Shift clustering\n",
    "mean_shift = MeanShift(bandwidth=0.1) \n",
    "mean_shift.fit(normalized_data)\n",
    "labels = mean_shift.labels_\n",
    "cluster_centers = mean_shift.cluster_centers_\n",
    "original_scale_centers = scaler.inverse_transform(cluster_centers)\n",
    "\n",
    "print(\"Cluster labels:\", labels)\n",
    "print(\"Cluster centers (original scale):\", original_scale_centers)\n",
    "\n",
    "# 2D Plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "scatter = plt.scatter(data[:, 1], data[:, 0], c=data[:, 2], cmap='viridis', s=50, alpha=0.8)\n",
    "plt.scatter(original_scale_centers[:, 1], original_scale_centers[:, 0], \n",
    "            c='red', marker='X', s=200, label='Cluster Centers')\n",
    "plt.xlabel('RAAN (omega)')\n",
    "plt.ylabel('Inclination (i)')\n",
    "plt.title('2D Scatter Plot of Space Debris Clusters')\n",
    "plt.colorbar(scatter, label='Eccentricity (e)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 3D Plot\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(data[:, 1], data[:, 0], data[:, 2], c=labels, cmap='viridis', s=50, alpha=0.8)\n",
    "ax.scatter(original_scale_centers[:, 1], original_scale_centers[:, 0], original_scale_centers[:, 2], \n",
    "           c='red', marker='X', s=200, label='Cluster Centers')\n",
    "ax.set_xlabel('RAAN (omega)')\n",
    "ax.set_ylabel('Inclination (i)')\n",
    "ax.set_zlabel('Eccentricity (e)')\n",
    "ax.set_title('Fake Data')\n",
    "fig.colorbar(scatter, ax=ax, label='Cluster Labels')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "st2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
