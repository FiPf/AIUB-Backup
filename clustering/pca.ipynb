{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0d95f40",
   "metadata": {},
   "source": [
    "# PCA \n",
    "Data: all years, GEO, GTO, Followup\n",
    "1) Load data from *.det files, filter data\n",
    "2) Standardize data and run PCA\n",
    "3) Plot the cumulative explained variance to show many components capture at least 5% of the variance. \n",
    "4) Track the top 3 features in the first two principal components PC1 and PC2, count how often each of the original features appears across all years and orbit types. \n",
    "5) Make scatter plots with PC1/PC2. Make pairplots with original features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77131128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GEO 2002] PCs for 95% var: 6\n",
      "[GEO 2003] PCs for 95% var: 6\n",
      "[GEO 2004] PCs for 95% var: 6\n",
      "[GEO 2005] PCs for 95% var: 6\n",
      "[GEO 2006] PCs for 95% var: 6\n",
      "[GEO 2007] PCs for 95% var: 6\n",
      "[GEO 2008] PCs for 95% var: 5\n",
      "[GEO 2009] PCs for 95% var: 6\n",
      "[GEO 2010] PCs for 95% var: 6\n",
      "[GEO 2011] PCs for 95% var: 6\n",
      "[GEO 2012] PCs for 95% var: 5\n",
      "[GEO 2013] Skipped: only 1 samples after filtering\n",
      "[GEO 2014] PCs for 95% var: 4\n",
      "[GEO 2015] PCs for 95% var: 6\n",
      "[GEO 2016] PCs for 95% var: 6\n",
      "[GEO 2017] PCs for 95% var: 6\n",
      "[GEO 2018] PCs for 95% var: 6\n",
      "[GEO 2019] PCs for 95% var: 6\n",
      "[GEO 2020] PCs for 95% var: 6\n",
      "[GEO 2021] PCs for 95% var: 6\n",
      "[GEO 2022] PCs for 95% var: 6\n",
      "[GEO 2023] PCs for 95% var: 6\n",
      "[GTO 2002] PCs for 95% var: 6\n",
      "[GTO 2003] PCs for 95% var: 6\n",
      "[GTO 2004] PCs for 95% var: 6\n",
      "[GTO 2005] PCs for 95% var: 6\n",
      "[GTO 2006] PCs for 95% var: 6\n",
      "[GTO 2007] PCs for 95% var: 6\n",
      "[GTO 2008] PCs for 95% var: 6\n",
      "[GTO 2009] PCs for 95% var: 6\n",
      "[GTO 2010] PCs for 95% var: 6\n",
      "[GTO 2011] PCs for 95% var: 6\n",
      "[GTO 2012] PCs for 95% var: 5\n",
      "[GTO 2013] Skipped: only 1 samples after filtering\n",
      "[GTO 2014] PCs for 95% var: 4\n",
      "[GTO 2015] PCs for 95% var: 6\n",
      "[GTO 2016] PCs for 95% var: 6\n",
      "[GTO 2017] PCs for 95% var: 6\n",
      "[GTO 2018] PCs for 95% var: 6\n",
      "[GTO 2019] PCs for 95% var: 6\n",
      "[GTO 2020] PCs for 95% var: 6\n",
      "[GTO 2021] PCs for 95% var: 6\n",
      "[GTO 2022] PCs for 95% var: 6\n",
      "[GTO 2023] PCs for 95% var: 6\n",
      "[FOL 2002] PCs for 95% var: 6\n",
      "[FOL 2003] PCs for 95% var: 7\n",
      "[FOL 2004] PCs for 95% var: 7\n",
      "[FOL 2005] PCs for 95% var: 6\n",
      "[FOL 2006] PCs for 95% var: 6\n",
      "[FOL 2007] PCs for 95% var: 6\n",
      "[FOL 2008] PCs for 95% var: 6\n",
      "[FOL 2009] PCs for 95% var: 6\n",
      "[FOL 2010] PCs for 95% var: 6\n",
      "[FOL 2011] PCs for 95% var: 6\n",
      "[FOL 2012] PCs for 95% var: 6\n",
      "[FOL 2013] PCs for 95% var: 5\n",
      "[FOL 2014] PCs for 95% var: 6\n",
      "[FOL 2015] PCs for 95% var: 6\n",
      "[FOL 2016] PCs for 95% var: 6\n",
      "[FOL 2017] PCs for 95% var: 6\n",
      "[FOL 2018] PCs for 95% var: 6\n",
      "[FOL 2019] PCs for 95% var: 6\n",
      "[FOL 2020] PCs for 95% var: 6\n",
      "[FOL 2021] PCs for 95% var: 6\n",
      "[FOL 2022] PCs for 95% var: 7\n",
      "[FOL 2023] PCs for 95% var: 6\n",
      "Feature importance frequency across PC1/PC2 top-3:\n",
      "  ecc: 78\n",
      "  mag_obj: 77\n",
      "  sem_major: 75\n",
      "  diameter: 65\n",
      "  inc: 42\n",
      "  raan: 21\n",
      "  true_lat: 17\n",
      "  arg_per: 9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load helper\n",
    "path_to_parent = os.path.abspath(\"..\")\n",
    "sys.path.append(path_to_parent)\n",
    "import getdata\n",
    "\n",
    "# Settings\n",
    "orbits = [\"geo\", \"gto\", \"fol\"]\n",
    "years = np.arange(2002, 2024)\n",
    "\n",
    "plot_dir = \"Images/pca\"\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "getdata.clear_directory(plot_dir)\n",
    "\n",
    "# PCA analysis and plotting\n",
    "\n",
    "# Track feature importance frequency\n",
    "from collections import Counter\n",
    "importance_counter = Counter()\n",
    "\n",
    "for orbit in orbits:\n",
    "    for year in years:\n",
    "        try:\n",
    "            # Build input filename\n",
    "            yy = str(year)[2:]\n",
    "            if year == 2023:\n",
    "                file = os.path.join(\"..\", \"input\", f\"stat_Master_23_{orbit}_s1_10cm.det\")\n",
    "            else:\n",
    "                file = os.path.join(\"..\", \"input\", f\"stat_Master_{yy}_{orbit}_s1.det\")\n",
    "\n",
    "            data = np.array(getdata.array_extender(file)).T\n",
    "\n",
    "            # Feature indices and names\n",
    "            orbit_feature_indices = [1, 8, 9, 10, 11, 12, 13, 20]\n",
    "            feature_names = [\n",
    "                \"diameter\", \"sem_major\", \"inc\", \"ecc\", \"arg_per\", \"raan\", \"true_lat\", \"mag_obj\"\n",
    "            ]\n",
    "\n",
    "            # Build DataFrame and adjust RAAN\n",
    "            df = pd.DataFrame(data[:, orbit_feature_indices], columns=feature_names)\n",
    "            df['raan'] = ((df['raan'] + 180) % 360) - 180\n",
    "\n",
    "            # Apply filters\n",
    "            df_filtered = df[\n",
    "                (df['mag_obj'] >= 14.5) & (df['mag_obj'] <= 19) &\n",
    "                (df['sem_major'] < 60000) &\n",
    "                (df['inc'] < 22) &\n",
    "                (df['diameter'] > 0.1)\n",
    "            ].reset_index(drop=True)\n",
    "\n",
    "            if len(df_filtered) < 2:\n",
    "                print(f\"[{orbit.upper()} {year}] Skipped: only {len(df_filtered)} samples after filtering\")\n",
    "                continue\n",
    "\n",
    "            # Standardize data\n",
    "            scaler = StandardScaler()\n",
    "            scaled = scaler.fit_transform(df_filtered)\n",
    "\n",
    "            # Perform PCA\n",
    "            n_comp = min(scaled.shape)\n",
    "            pca = PCA(n_components=n_comp)\n",
    "            components = pca.fit_transform(scaled)\n",
    "            explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "            # Plot cumulative variance\n",
    "            cum_var = np.cumsum(explained_variance)\n",
    "            plt.figure()\n",
    "            plt.plot(cum_var, marker='o')\n",
    "            plt.axhline(0.95, linestyle='--', color='r')\n",
    "            plt.xlabel('Number of Principal Components')\n",
    "            plt.ylabel('Cumulative Explained Variance')\n",
    "            plt.title(f'PCA Explained Variance ({orbit.upper()}, {year})')\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(plot_dir, f\"cumvar_{orbit}_{year}.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            # Determine number of PCs capturing 95% variance\n",
    "            num_pc = np.argmax(cum_var >= 0.95) + 1\n",
    "            print(f\"[{orbit.upper()} {year}] PCs for 95% var: {num_pc}\")\n",
    "\n",
    "            # Prepare top-3 loadings for PC1 and PC2\n",
    "            legends = []\n",
    "            for comp_idx in [0, 1]:\n",
    "                loadings = np.abs(pca.components_[comp_idx])\n",
    "                feat_loads = list(zip(feature_names, loadings))\n",
    "                # record top feature names in global counter\n",
    "                top3 = sorted(feat_loads, key=lambda x: x[1], reverse=True)[:3]\n",
    "                for name, _ in top3:\n",
    "                    importance_counter[name] += 1\n",
    "                labels = [f\"{name} ({coef:.2f})\" for name, coef in top3]\n",
    "                legends.append(f\"PC{comp_idx+1}: \" + \", \".join(labels))\n",
    "\n",
    "            # Single scatter plot with combined legend\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.scatter(components[:, 0], components[:, 1], s=5, alpha=0.7)\n",
    "            plt.xlabel('PC1')\n",
    "            plt.ylabel('PC2')\n",
    "            plt.title(f'PC1 vs PC2 ({orbit.upper()}, {year})')\n",
    "            for i, text in enumerate(legends):\n",
    "                plt.text(0.05, 0.95 - i*0.05, text, transform=plt.gca().transAxes,\n",
    "                         fontsize='small', va='top')\n",
    "            plt.grid(which='both', linestyle='--', linewidth=0.5)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(plot_dir, f\"scatter_pc1_pc2_{orbit}_{year}.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            # Pairplot of features\n",
    "            g = sns.PairGrid(df_filtered, diag_sharey=False)\n",
    "            g.map_upper(sns.scatterplot, s=10)\n",
    "            g.map_diag(sns.histplot, kde=False)\n",
    "            for i, y_var in enumerate(feature_names):\n",
    "                for j, x_var in enumerate(feature_names):\n",
    "                    ax = g.axes[i, j]\n",
    "                    if j < i:\n",
    "                        ax.set_visible(False)\n",
    "                    else:\n",
    "                        ax.set_xlabel(x_var)\n",
    "                        ax.set_ylabel(y_var)\n",
    "            g.fig.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "            g.fig.suptitle(f'Pairplot ({orbit.upper()}, {year})', y=1.02)\n",
    "            g.fig.tight_layout()\n",
    "            g.fig.savefig(os.path.join(plot_dir, f\"pairplot_{orbit}_{year}.png\"))\n",
    "            plt.close(g.fig)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[{orbit.upper()} {year}] Failed: {e}\")\n",
    "\n",
    "# After all runs, print most frequently important features\n",
    "print(\"Feature importance frequency across PC1/PC2 top-3:\")\n",
    "for feature, count in importance_counter.most_common():\n",
    "    print(f\"  {feature}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fe39f5",
   "metadata": {},
   "source": [
    "# PCA dominant features: loadings and over time  \n",
    "1) Load and filter detection data. \n",
    "2) Standardize data and run PCA. \n",
    "3) Record the fraction of the variance explaind by PC1 and the feature loadings for PC1. \n",
    "4) Store results in dataframe and crease plots:   \n",
    "    a) How much of the variance PC1 explains over time (one plot point per year), make three curves for GEO, GTO and Followup.   \n",
    "    b) Heatmaps of the PC1 feature loadings over time for each orbit type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af520a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\fionu\\AppData\\Local\\Temp\\ipykernel_19620\\3618191254.py:13: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  STORE_FOLDER = \"Images\\pca_and_pairplots\"\n",
      "c:\\Users\\fionu\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:591: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\fionu\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:591: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "YEARS       = list(range(2002, 2024))\n",
    "ORBIT_TYPES = [\"geo\", \"gto\", \"fol\"]\n",
    "BASE_DIR    = os.path.join(\"..\", \"input\")\n",
    "\n",
    "STORE_FOLDER = \"Images\\pca_and_pairplots\"\n",
    "os.makedirs(STORE_FOLDER, exist_ok=True)\n",
    "getdata.clear_directory(STORE_FOLDER)\n",
    "\n",
    "# indices & feature names\n",
    "ORBIT_IDX = [1, 8, 9, 10, 11, 12, 13, 20]\n",
    "FEATURES = [\"diameter\", \"sem_major\", \"inc\", \"ecc\", \"arg_per\", \"raan\", \"true_lat\", \"mag_obj\"]\n",
    "\n",
    "# Clear and create storage folder\n",
    "getdata.clear_directory(STORE_FOLDER)\n",
    "os.makedirs(STORE_FOLDER, exist_ok=True)\n",
    "\n",
    "# Fundamental filters\n",
    "def apply_filters(df):\n",
    "    df = df.copy()\n",
    "    df['raan'] = ((df['raan'] + 180) % 360) - 180\n",
    "    return df[\n",
    "        (df.mag_obj.between(14.5, 19)) &\n",
    "        (df.sem_major < 60000) &\n",
    "        (df.inc < 22) &\n",
    "        (df.diameter > 0.1)\n",
    "    ]\n",
    "\n",
    "# PCA runner\n",
    "def run_pca_for(year: int, orbit: str):\n",
    "    year2 = str(year)[2:]\n",
    "    if year == 2023:\n",
    "        path = os.path.join(BASE_DIR, f\"stat_Master_23_{orbit}_s1_10cm.det\").replace(\"\\\\\", \"/\")\n",
    "    else:\n",
    "        path = os.path.join(BASE_DIR, f\"stat_Master_{year2}_{orbit}_s1.det\").replace(\"\\\\\", \"/\")\n",
    "\n",
    "    raw = np.array(getdata.array_extender(path)).T\n",
    "    df = pd.DataFrame(raw[:, ORBIT_IDX], columns=FEATURES)\n",
    "    df_f = apply_filters(df)\n",
    "    X = StandardScaler().fit_transform(df_f)\n",
    "\n",
    "    n_comp = min(X.shape[0], X.shape[1])\n",
    "    pca = PCA(n_components=n_comp).fit(X)\n",
    "\n",
    "    cumvar = np.cumsum(pca.explained_variance_ratio_)\n",
    "    n95 = np.searchsorted(cumvar, 0.95) + 1\n",
    "    load1 = pca.components_[0]\n",
    "\n",
    "    return {\n",
    "        \"year\": year,\n",
    "        \"orbit\": orbit,\n",
    "        \"n_samples\": X.shape[0],\n",
    "        \"n95\": n95,\n",
    "        \"pc1_var\": cumvar[0],\n",
    "        **{f\"load1_{f}\": load for f, load in zip(FEATURES, load1)}\n",
    "    }\n",
    "\n",
    "# Collect results\n",
    "results = []\n",
    "for orb in ORBIT_TYPES:\n",
    "    for yr in YEARS:\n",
    "        try:\n",
    "            meta = run_pca_for(yr, orb)\n",
    "            results.append(meta)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed {orb} {yr}: {e}\")\n",
    "\n",
    "df_res = pd.DataFrame(results)\n",
    "\n",
    "# Plot: PC1 variance ratio over time\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(data=df_res, x=\"year\", y=\"pc1_var\", hue=\"orbit\", marker=\"o\")\n",
    "plt.title(\"Fraction of Variance explained by PC1 over time\")\n",
    "plt.ylabel(\"PC1 Variance Ratio\")\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(STORE_FOLDER, \"pc1_variance_over_time.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Plot: PC1 loadings heatmap for each orbit\n",
    "for orb in ORBIT_TYPES:\n",
    "    pivot = (df_res[df_res.orbit == orb]\n",
    "             .set_index(\"year\")[[f\"load1_{f}\" for f in FEATURES]])\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(pivot, center=0, cmap=\"coolwarm\", annot=True, fmt=\".2f\")\n",
    "    plt.title(f\"PC1 Loadings ({orb.upper()})\")\n",
    "    plt.tight_layout()\n",
    "    filename = f\"pc1_loadings_{orb}.png\"\n",
    "    plt.savefig(os.path.join(STORE_FOLDER, filename))\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
