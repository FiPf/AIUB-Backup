{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "267e3e45",
   "metadata": {},
   "source": [
    "## Tasks after the IAC paper has been finished, given 17.09.2025 by Nicola\n",
    "\n",
    "1) Side activity: Filter observed data by magnitudes (only keep objects with mag 14.5 to 19)  \n",
    "2) Observed data: Run DBSCAN on other time windows than 2005-2008 (shift by one year, near the original window), produce 2D plots and pairplots  \n",
    "3) Correlate objects in clusters with DISCOS fragementation events, consider passed time and typical evolution path, find consitencies  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0135eac",
   "metadata": {},
   "source": [
    "## 1) Side activity: Filter observed data by magnitudes (only keep objects with mag 14.5 to 19)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c6f2b9",
   "metadata": {},
   "source": [
    "### Observation plots in 2D, DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a5b6357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as: Images/IAC_plots_followup/DBSCAN_2d_observed\\dbscan_2005-2008_eps0.015_min15_observed_2.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cluster_data\n",
    "from cluster_data import normalize_data, unnormalize\n",
    "from cluster_plotter import ClusterPlotter\n",
    "from DBSCAN import dbscan_clustering \n",
    "\n",
    "# Define observed files\n",
    "uncorr_obs_files = {\n",
    "    year: f\"ogs{year}01_12_det.ele_ucorr\" if year != 2002 else f\"ogs{year}08_12_det.ele_ucorr\"\n",
    "    for year in range(2002, 2024) if year != 2018  # Exclude 2018 if missing\n",
    "}\n",
    "\n",
    "# Use running ranges\n",
    "IAC_range = {\"2005-2008\": np.arange(2005, 2009)}\n",
    "year_ranges = IAC_range\n",
    "\n",
    "# Bin the observed data\n",
    "binned_data = cluster_data.bin_observed_data(uncorr_obs_files, year_ranges, print_res=False)\n",
    "\n",
    "# Output directory for plots\n",
    "plot_dir = \"Images/IAC_plots_followup/DBSCAN_2d_observed\"\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "for cluster_data, year_range in binned_data:\n",
    "    data_array = np.array([cluster_data.inc, cluster_data.raan]).T\n",
    "    normalized_data, data_min, data_max = normalize_data(data_array)\n",
    "    \n",
    "    eps_values = [0.015]\n",
    "    min_samples_values = [15]\n",
    "    \n",
    "    for eps in eps_values:\n",
    "        for min_samples in min_samples_values:\n",
    "            result_dbscan = dbscan_clustering(\n",
    "                normalized_data, eps=eps, min_samples=min_samples\n",
    "            )\n",
    "\n",
    "            unnormalized_data, cluster_centers = unnormalize(\n",
    "                result_dbscan.data, result_dbscan.cluster_centers, data_min, data_max\n",
    "            )\n",
    "            \n",
    "            plotter = ClusterPlotter(unnormalized_data, result_dbscan.labels, cluster_centers)\n",
    "            plotter.clusters_2d_plot(\n",
    "                f\"DBSCAN: years = {year_range}, eps = {eps}, min_samples = {min_samples}\",\n",
    "                os.path.join(plot_dir, f\"dbscan_{year_range}_eps{eps}_min{min_samples}_observed.png\")\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e415ad4",
   "metadata": {},
   "source": [
    "### Observation plots in 2D+, DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b631cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:47: SyntaxWarning: invalid escape sequence '\\O'\n",
      "<>:47: SyntaxWarning: invalid escape sequence '\\O'\n",
      "C:\\Users\\fionu\\AppData\\Local\\Temp\\ipykernel_7964\\1575974451.py:47: SyntaxWarning: invalid escape sequence '\\O'\n",
      "  \"\"\"axis_labels = {\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running DBSCAN 9D for Year Range: 2005-2008\n",
      "Runtime for dbscan_clustering: 0.085649 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cluster_data_pca_08072025 as cdp\n",
    "from cluster_data_pca_08072025 import run_clustering, normalize_data\n",
    "from DBSCAN import dbscan_clustering\n",
    "import cluster_plotter\n",
    "\n",
    "# --- Style settings ---\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 16,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"axes.titlesize\": 18,\n",
    "    \"legend.fontsize\": 14,\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14\n",
    "})\n",
    "\n",
    "# --- Setup ---\n",
    "year_range = \"2005-2008\"\n",
    "plot_dir = \"Images/IAC_plots_followup/DBSCAN_2Dplus_observed\"\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "cluster_plotter.clear_directory(plot_dir)\n",
    "\n",
    "# --- Load observed data ---\n",
    "uncorr_obs_files = {\n",
    "    year: f\"ogs{year}01_12_det.ele_ucorr\" if year != 2002 else f\"ogs{year}08_12_det.ele_ucorr\"\n",
    "    for year in range(2002, 2024) if year != 2018\n",
    "}\n",
    "year_ranges = {year_range: np.arange(2005, 2009)}\n",
    "binned_data = cdp.bin_observed_data(uncorr_obs_files, year_ranges, print_res=False)\n",
    "\n",
    "# --- DBSCAN parameters ---\n",
    "eps_values = [0.11]\n",
    "min_samples_values = [12]\n",
    "\n",
    "# --- Color palette ---\n",
    "extreme_colors = [\n",
    "    \"#3DC53D\", \"#4F4FF3\", '#FFFF00', \"#A148A1\", '#00FFFF',\n",
    "    '#FF8000', '#8000FF', \"#F157A4\", '#00FF80', '#804000', '#000000',\n",
    "    '#808080', '#404040', \"#FF000094\"\n",
    "]\n",
    "\n",
    "# --- Axis labels ---\n",
    "\"\"\"axis_labels = {\n",
    "    \"ecc\": r\"$e$\",\n",
    "    \"sem_maj\": r\"$a$ [km]\", \n",
    "    \"inc\": r\"$i$ [°]\", \n",
    "    \"raan\": r\"$\\Omega$ [°]\",\n",
    "    \"perigee\": r\"\\omega [°]\",\n",
    "    \"arg lat\": r\"$\\lambda$ [°]\",\n",
    "    \"mean motion\": r\"$n$ [rev/day]\", \n",
    "    \"mag_obj\": r\"$m$\", \n",
    "    \"diameter\": r\"$d$ [m]\"\n",
    "}\"\"\"\n",
    "\n",
    "axis_labels = {\n",
    "    \"mean motion\": r\"$n$ [rev/day]\",\n",
    "    \"ecc\": r\"$e$\",\n",
    "    \"inc\": r\"$i$ [°]\",\n",
    "    \"raan\": r\"$\\Omega$ [°]\",\n",
    "    \"arg lat\": r\"$\\lambda$ [°]\",\n",
    "    \"mag\": r\"$m$\"\n",
    "}\n",
    "\n",
    "# --- Run DBSCAN ---\n",
    "for cluster_data, year_range in binned_data:\n",
    "    print(f\"\\nRunning DBSCAN 9D for Year Range: {year_range}\")\n",
    "\n",
    "    # --- Full feature set (9D) ---\n",
    "    X_all = np.vstack([\n",
    "        cluster_data.sem_maj,\n",
    "        cluster_data.inc,\n",
    "        cluster_data.raan,\n",
    "        cluster_data.true_lat,\n",
    "        cluster_data.mean_motion,\n",
    "        cluster_data.mag_obj,\n",
    "    ]).T\n",
    "\n",
    "    X_plot = np.vstack([\n",
    "        cluster_data.mean_motion,\n",
    "        cluster_data.inc,\n",
    "        cluster_data.raan,\n",
    "        cluster_data.true_lat,\n",
    "        cluster_data.mag_obj\n",
    "    ]).T\n",
    "\n",
    "    norm_X_all, X_min, X_max = normalize_data(X_all)\n",
    "\n",
    "    for eps in eps_values:\n",
    "        for min_samples in min_samples_values:\n",
    "            # --- Run DBSCAN ---\n",
    "            clustering, duration, n_clusters, pts_per_cluster, _ = run_clustering(\n",
    "                dbscan_clustering, \"DBSCAN\", norm_X_all, X_min, X_max,\n",
    "                eps=eps, min_samples=min_samples\n",
    "            )\n",
    "            labels = clustering.labels\n",
    "\n",
    "            # --- Remap cluster labels ---\n",
    "            unique_labels = sorted(set(labels) - {-1})\n",
    "            label_map = {old: i+1 for i, old in enumerate(unique_labels)}\n",
    "            label_map[-1] = \"Noise\"\n",
    "            mapped_labels = [label_map[l] for l in labels]\n",
    "\n",
    "            # --- Build dataframe ---\n",
    "            \"\"\"df = pd.DataFrame(X_plot, columns=[\n",
    "                \"ecc\", \"sem_maj\", \"inc\", \"raan\", \"perigee\", \"arg lat\",\n",
    "                \"mean motion\", \"mag_obj\", \"diameter\"\n",
    "            ])\"\"\"\n",
    "            df = pd.DataFrame(X_plot, columns=[\n",
    "                \"mean motion\", \"inc\", \"raan\", \"arg lat\", \"mag\"\n",
    "            ])\n",
    "            df['cluster'] = mapped_labels\n",
    "\n",
    "            # --- Pairplot ---\n",
    "                # --- Pairplot with extreme contrast colors ---\n",
    "            palette_map = {i+1: extreme_colors[i % len(extreme_colors)] \n",
    "               for i in range(len(unique_labels))}\n",
    "            if -1 in labels:\n",
    "                palette_map[\"Noise\"] = \"red\"\n",
    "\n",
    "\n",
    "            pp = sns.pairplot(\n",
    "                df, hue='cluster', diag_kind='kde',\n",
    "                plot_kws={'alpha': 0.8, 's': 15, 'marker': 'o', 'edgecolor': None},\n",
    "                corner=True,\n",
    "                hue_order=[*range(1, len(unique_labels)+1)] + ([\"Noise\"] if -1 in labels else []),\n",
    "                palette=palette_map\n",
    "            )\n",
    "\n",
    "\n",
    "            # --- Set LaTeX labels ---\n",
    "            for ax in pp.axes.flatten():\n",
    "                if ax is not None:\n",
    "                    xlabel = ax.get_xlabel()\n",
    "                    ylabel = ax.get_ylabel()\n",
    "                    if xlabel in axis_labels:\n",
    "                        ax.set_xlabel(axis_labels[xlabel])\n",
    "                    if ylabel in axis_labels:\n",
    "                        ax.set_ylabel(axis_labels[ylabel])\n",
    "\n",
    "            # Diagonal labels\n",
    "            for i, var in enumerate(pp.x_vars):\n",
    "                ax = pp.axes[i, i]\n",
    "                if ax is not None and var in axis_labels:\n",
    "                    ax.set_xlabel(axis_labels[var])\n",
    "                    ax.set_ylabel(axis_labels[var])\n",
    "\n",
    "            # --- Legend ---\n",
    "            for lh in pp._legend.legend_handles:\n",
    "                lh.set_markersize(20)\n",
    "                lh.set_alpha(1.0)\n",
    "                lh.set_markeredgewidth(0)\n",
    "            pp._legend.set_title(\"Cluster\", prop={'size': 17})\n",
    "            for text in pp._legend.get_texts():\n",
    "                text.set_fontsize(17)\n",
    "            pp._legend.set_bbox_to_anchor((0.87, 0.6))\n",
    "            pp._legend.set_frame_on(True)     \n",
    "            pp._legend.get_frame().set_edgecolor(\"grey\")\n",
    "            pp._legend.get_frame().set_linewidth(1.0)\n",
    "\n",
    "            # --- Title & save ---\n",
    "            \"\"\"pp.fig.suptitle(\n",
    "                f\"DBSCAN 6D→5D Clusters {year_range} (eps={eps}, ms={min_samples})\",\n",
    "                y=1.02, fontsize=20\n",
    "            )\"\"\"\n",
    "\n",
    "            fname = f\"pairplot_{year_range}_eps{eps}_ms{min_samples}_observed.png\"\n",
    "            pp.savefig(os.path.join(plot_dir, fname), bbox_inches=\"tight\", transparent=False)\n",
    "            plt.close(pp.fig)\n",
    "\n",
    "            # --- Additional 2D semi-major axis distribution plot ---\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            sns.kdeplot(cluster_data.sem_maj, fill=True, color=\"skyblue\", linewidth=2)\n",
    "            plt.xlabel(r\"$a$ [km]\", fontsize=16)\n",
    "            plt.ylabel(\"Density\", fontsize=16)\n",
    "            plt.title(f\"Semi-Major Axis Distribution {year_range} (eps={eps}, ms={min_samples})\", fontsize=14)\n",
    "            fname_sma = f\"sma_distribution_{year_range}_eps{eps}_ms{min_samples}.png\"\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(plot_dir, fname_sma), transparent=False)\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a27b550",
   "metadata": {},
   "source": [
    "### Observation plots in 2D+, DBSCAN, small clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "649555b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running DBSCAN 9D for Year Range: 2005-2008\n",
      "Runtime for dbscan_clustering: 0.084356 seconds\n",
      "\n",
      "Removed clusters for eps=0.11, min_samples=12:\n",
      "  Cluster 1: 2175 points\n",
      "  Cluster Noise: 1756 points\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cluster_data_pca_08072025 as cdp\n",
    "from cluster_data_pca_08072025 import run_clustering, normalize_data\n",
    "from DBSCAN import dbscan_clustering\n",
    "import cluster_plotter\n",
    "\n",
    "# --- Style settings ---\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 16,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"axes.titlesize\": 18,\n",
    "    \"legend.fontsize\": 14,\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14\n",
    "})\n",
    "\n",
    "# --- Setup ---\n",
    "year_range = \"2005-2008\"\n",
    "plot_dir = \"Images/IAC_plots_followup/DBSCAN_2Dplus_observed_smallclusters\"\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "cluster_plotter.clear_directory(plot_dir)\n",
    "\n",
    "# --- Load observed data ---\n",
    "uncorr_obs_files = {\n",
    "    year: f\"ogs{year}01_12_det.ele_ucorr\" if year != 2002 else f\"ogs{year}08_12_det.ele_ucorr\"\n",
    "    for year in range(2002, 2024) if year != 2018\n",
    "}\n",
    "year_ranges = {year_range: np.arange(2005, 2009)}\n",
    "binned_data = cdp.bin_observed_data(uncorr_obs_files, year_ranges, print_res=False)\n",
    "\n",
    "# --- DBSCAN parameters ---\n",
    "eps_values = [0.11]\n",
    "min_samples_values = [12]\n",
    "\n",
    "# --- Extreme contrast color scheme (original cluster order) ---\n",
    "extreme_colors = [\n",
    "    \"#3DC53D\", \"#4F4FF3\", '#FFFF00', \"#A148A1\", '#00FFFF',\n",
    "    '#FF8000', '#8000FF', \"#F157A4\", '#00FF80', '#804000', '#000000',\n",
    "    '#808080', '#404040', \"#FF000094\"\n",
    "]\n",
    "\n",
    "# --- Axis labels ---\n",
    "axis_labels = {\n",
    "    \"mean motion\": r\"$n$ [rev/day]\",\n",
    "    \"ecc\": r\"$e$\",\n",
    "    \"inc\": r\"$i$ [°]\",\n",
    "    \"raan\": r\"$\\Omega$ [°]\",\n",
    "    \"arg lat\": r\"$\\lambda$ [°]\",\n",
    "    \"mag\": r\"$m$\"\n",
    "}\n",
    "\n",
    "# --- Run DBSCAN ---\n",
    "for cluster_data, year_range in binned_data:\n",
    "    print(f\"\\nRunning DBSCAN 9D for Year Range: {year_range}\")\n",
    "\n",
    "    # --- Full feature set (9D) ---\n",
    "    X_all = np.vstack([\n",
    "        cluster_data.sem_maj,\n",
    "        cluster_data.inc,\n",
    "        cluster_data.raan,\n",
    "        cluster_data.true_lat,\n",
    "        cluster_data.mean_motion,\n",
    "        cluster_data.mag_obj\n",
    "    ]).T\n",
    "\n",
    "    # --- Subset for plotting (5D) ---\n",
    "    X_plot = np.vstack([\n",
    "        cluster_data.mean_motion,\n",
    "        cluster_data.inc,\n",
    "        cluster_data.raan,\n",
    "        cluster_data.true_lat,\n",
    "        cluster_data.mag_obj\n",
    "    ]).T\n",
    "\n",
    "    norm_X_all, X_min, X_max = normalize_data(X_all)\n",
    "\n",
    "    for eps in eps_values:\n",
    "        for min_samples in min_samples_values:\n",
    "            # --- Run clustering ---\n",
    "            clustering, duration, n_clusters, pts_per_cluster, _ = run_clustering(\n",
    "                dbscan_clustering, \"DBSCAN\", norm_X_all, X_min, X_max,\n",
    "                eps=eps, min_samples=min_samples\n",
    "            )\n",
    "            labels = clustering.labels\n",
    "\n",
    "            # --- Remap clusters to 1..N, Noise stays -1 ---\n",
    "            unique_labels = sorted(set(labels) - {-1})\n",
    "            label_map = {old: i+1 for i, old in enumerate(unique_labels)}\n",
    "            label_map[-1] = \"Noise\"\n",
    "            mapped_labels = [label_map[l] for l in labels]\n",
    "\n",
    "            # --- Build DataFrame ---\n",
    "            df = pd.DataFrame(X_plot, columns=[\n",
    "                \"mean motion\", \"inc\", \"raan\", \"arg lat\", \"mag\"\n",
    "            ])\n",
    "            df['cluster'] = mapped_labels\n",
    "\n",
    "            # --- Remove largest cluster + Noise ---\n",
    "            cluster_sizes = df['cluster'].value_counts()\n",
    "            non_noise_clusters = cluster_sizes.drop(labels=[\"Noise\"], errors=\"ignore\")\n",
    "            clusters_to_remove = []\n",
    "            if not non_noise_clusters.empty:\n",
    "                largest_cluster = non_noise_clusters.idxmax()\n",
    "                clusters_to_remove.append(largest_cluster)\n",
    "            if \"Noise\" in cluster_sizes.index:\n",
    "                clusters_to_remove.append(\"Noise\")\n",
    "\n",
    "            print(f\"\\nRemoved clusters for eps={eps}, min_samples={min_samples}:\")\n",
    "            for cl in clusters_to_remove:\n",
    "                print(f\"  Cluster {cl}: {cluster_sizes[cl]} points\")\n",
    "\n",
    "            df = df[~df['cluster'].isin(clusters_to_remove)]\n",
    "\n",
    "            # --- Original palette mapping ---\n",
    "            original_palette_map = {i+1: extreme_colors[i % len(extreme_colors)] for i in range(len(extreme_colors))}\n",
    "            if \"Noise\" in df['cluster'].unique():\n",
    "                original_palette_map[\"Noise\"] = \"red\"\n",
    "\n",
    "            # --- Keep only remaining clusters in the palette ---\n",
    "            remaining_clusters = df['cluster'].unique()\n",
    "            palette_map = {cl: original_palette_map[cl] for cl in remaining_clusters}\n",
    "\n",
    "            # --- Hue order: numeric clusters in order, then Noise if present ---\n",
    "            numeric_clusters = sorted([cl for cl in remaining_clusters if isinstance(cl, int)])\n",
    "            hue_order = numeric_clusters\n",
    "            if \"Noise\" in remaining_clusters:\n",
    "                hue_order.append(\"Noise\")\n",
    "\n",
    "            # --- Pairplot ---\n",
    "            pp = sns.pairplot(\n",
    "                df, hue='cluster', diag_kind='kde',\n",
    "                plot_kws={'alpha': 0.8, 's': 15, 'marker': 'o', 'edgecolor': None},\n",
    "                corner=True,\n",
    "                hue_order=hue_order,\n",
    "                palette=palette_map\n",
    "            )\n",
    "\n",
    "            # --- LaTeX labels ---\n",
    "            for ax in pp.axes.flatten():\n",
    "                if ax is not None:\n",
    "                    xlabel = ax.get_xlabel()\n",
    "                    ylabel = ax.get_ylabel()\n",
    "                    if xlabel in axis_labels:\n",
    "                        ax.set_xlabel(axis_labels[xlabel])\n",
    "                    if ylabel in axis_labels:\n",
    "                        ax.set_ylabel(axis_labels[ylabel])\n",
    "\n",
    "            # Diagonal labels\n",
    "            for i, var in enumerate(pp.x_vars):\n",
    "                ax = pp.axes[i, i]\n",
    "                if ax is not None and var in axis_labels:\n",
    "                    ax.set_xlabel(axis_labels[var])\n",
    "                    ax.set_ylabel(axis_labels[var])\n",
    "\n",
    "            # --- Legend ---\n",
    "            for lh in pp._legend.legend_handles:\n",
    "                lh.set_markersize(20)\n",
    "                lh.set_alpha(1.0)\n",
    "                lh.set_markeredgewidth(0)\n",
    "            pp._legend.set_title(\"Cluster\", prop={'size': 17})\n",
    "            for text in pp._legend.get_texts():\n",
    "                text.set_fontsize(17)\n",
    "            pp._legend.set_bbox_to_anchor((0.9, 0.6))\n",
    "            pp._legend.set_frame_on(True)     \n",
    "            pp._legend.get_frame().set_edgecolor(\"grey\")\n",
    "            pp._legend.get_frame().set_linewidth(1.0)\n",
    "\n",
    "            # --- Save ---\n",
    "            fname = f\"pairplot_{year_range}_eps{eps}_ms{min_samples}_observed_smallclusters.png\"\n",
    "            pp.savefig(os.path.join(plot_dir, fname), transparent=False)\n",
    "            plt.close(pp.fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b585fa",
   "metadata": {},
   "source": [
    "## 2) Observed data: Run DBSCAN on other time windows than 2005-2008 (shift by one year, near the original window), produce 2D plots and pairplots  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb0e2ed",
   "metadata": {},
   "source": [
    "### Observation plots in 2D, DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33c282e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as: Images/IAC_plots_followup/DBSCAN_2d_observed\\dbscan_2002_2005_eps0.015_min15_observed_1.png\n",
      "Plot saved as: Images/IAC_plots_followup/DBSCAN_2d_observed\\dbscan_2003_2006_eps0.015_min15_observed_1.png\n",
      "Plot saved as: Images/IAC_plots_followup/DBSCAN_2d_observed\\dbscan_2004_2007_eps0.015_min15_observed_1.png\n",
      "Plot saved as: Images/IAC_plots_followup/DBSCAN_2d_observed\\dbscan_2005_2008_eps0.015_min15_observed_1.png\n",
      "Plot saved as: Images/IAC_plots_followup/DBSCAN_2d_observed\\dbscan_2006_2009_eps0.015_min15_observed_1.png\n",
      "Plot saved as: Images/IAC_plots_followup/DBSCAN_2d_observed\\dbscan_2007_2010_eps0.015_min15_observed_1.png\n",
      "Plot saved as: Images/IAC_plots_followup/DBSCAN_2d_observed\\dbscan_2008_2011_eps0.015_min15_observed_1.png\n",
      "Plot saved as: Images/IAC_plots_followup/DBSCAN_2d_observed\\dbscan_2009_2012_eps0.015_min15_observed_1.png\n",
      "Plot saved as: Images/IAC_plots_followup/DBSCAN_2d_observed\\dbscan_2010_2013_eps0.015_min15_observed.png\n",
      "Plot saved as: Images/IAC_plots_followup/DBSCAN_2d_observed\\dbscan_2011_2014_eps0.015_min15_observed.png\n",
      "Plot saved as: Images/IAC_plots_followup/DBSCAN_2d_observed\\dbscan_2012_2015_eps0.015_min15_observed.png\n",
      "Plot saved as: Images/IAC_plots_followup/DBSCAN_2d_observed\\dbscan_2013_2016_eps0.015_min15_observed.png\n",
      "Plot saved as: Images/IAC_plots_followup/DBSCAN_2d_observed\\dbscan_2014_2017_eps0.015_min15_observed.png\n",
      "Plot saved as: Images/IAC_plots_followup/DBSCAN_2d_observed\\dbscan_2015_2018_eps0.015_min15_observed.png\n",
      "Plot saved as: Images/IAC_plots_followup/DBSCAN_2d_observed\\dbscan_2016_2019_eps0.015_min15_observed.png\n",
      "Plot saved as: Images/IAC_plots_followup/DBSCAN_2d_observed\\dbscan_2017_2020_eps0.015_min15_observed.png\n",
      "Plot saved as: Images/IAC_plots_followup/DBSCAN_2d_observed\\dbscan_2018_2021_eps0.015_min15_observed.png\n",
      "Plot saved as: Images/IAC_plots_followup/DBSCAN_2d_observed\\dbscan_2019_2022_eps0.015_min15_observed.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cluster_data\n",
    "from cluster_data import normalize_data, unnormalize\n",
    "from cluster_plotter import ClusterPlotter\n",
    "from DBSCAN import dbscan_clustering \n",
    "\n",
    "# Define observed files\n",
    "uncorr_obs_files = {\n",
    "    year: f\"ogs{year}01_12_det.ele_ucorr\" if year != 2002 else f\"ogs{year}08_12_det.ele_ucorr\"\n",
    "    for year in range(2002, 2024) if year != 2018  # Exclude 2018 if missing\n",
    "}\n",
    "\n",
    "# Define 4-year ranges with 1-year overlap\n",
    "year_ranges = {\n",
    "    f\"{start}-{start+3}\": np.arange(start, start+4)\n",
    "    for start in range(2002, 2020) \n",
    "}\n",
    "\n",
    "# Bin the observed data\n",
    "binned_data = cluster_data.bin_observed_data(uncorr_obs_files, year_ranges, print_res=False)\n",
    "\n",
    "# Output directory for plots\n",
    "plot_dir = \"Images/IAC_plots_followup/DBSCAN_2d_observed\"\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "for cluster_data, year_range in binned_data:\n",
    "    data_array = np.array([cluster_data.inc, cluster_data.raan]).T\n",
    "    normalized_data, data_min, data_max = normalize_data(data_array)\n",
    "    \n",
    "    eps_values = [0.015]\n",
    "    min_samples_values = [15]\n",
    "    \n",
    "    for eps in eps_values:\n",
    "        for min_samples in min_samples_values:\n",
    "            result_dbscan = dbscan_clustering(\n",
    "                normalized_data, eps=eps, min_samples=min_samples\n",
    "            )\n",
    "\n",
    "            unnormalized_data, cluster_centers = unnormalize(\n",
    "                result_dbscan.data, result_dbscan.cluster_centers, data_min, data_max\n",
    "            )\n",
    "            \n",
    "            # clean file name (replace dash with underscore)\n",
    "            year_label = str(year_range).replace(\"-\", \"_\")\n",
    "            \n",
    "            plotter = ClusterPlotter(unnormalized_data, result_dbscan.labels, cluster_centers)\n",
    "            plotter.clusters_2d_plot(\n",
    "                f\"DBSCAN: years = {year_range}, eps = {eps}, min_samples = {min_samples}\",\n",
    "                os.path.join(plot_dir, f\"dbscan_{year_label}_eps{eps}_min{min_samples}_observed.png\")\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b091a33f",
   "metadata": {},
   "source": [
    "### Observations plots 2D+, DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "006ed900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fionu\\OneDrive\\Dokumente\\Daten Fiona\\AIUB\\Code\\AIUB-Backup\\clustering\\cluster_data_pca_08072025.py:335: RuntimeWarning: divide by zero encountered in divide\n",
      "  mm = np.sqrt(mu/(sem_maj*1000)**3) #convert semi major from km to m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running DBSCAN 9D for Year Range: 2002-2005\n",
      "Runtime for dbscan_clustering: 0.165776 seconds\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2003-2006\n",
      "Runtime for dbscan_clustering: 0.220740 seconds\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2004-2007\n",
      "Runtime for dbscan_clustering: 0.170042 seconds\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2005-2008\n",
      "Runtime for dbscan_clustering: 0.156841 seconds\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2006-2009\n",
      "Runtime for dbscan_clustering: 0.162911 seconds\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2007-2010\n",
      "Runtime for dbscan_clustering: 0.127922 seconds\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2008-2011\n",
      "Runtime for dbscan_clustering: 0.131074 seconds\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2009-2012\n",
      "Runtime for dbscan_clustering: 0.066947 seconds\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2010-2013\n",
      "Runtime for dbscan_clustering: 0.094511 seconds\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2011-2014\n",
      "Runtime for dbscan_clustering: 0.047018 seconds\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2012-2015\n",
      "Runtime for dbscan_clustering: 0.038534 seconds\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2013-2016\n",
      "Runtime for dbscan_clustering: 0.047494 seconds\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2014-2017\n",
      "Runtime for dbscan_clustering: 0.066458 seconds\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2015-2018\n",
      "Runtime for dbscan_clustering: 0.042714 seconds\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2016-2019\n",
      "Runtime for dbscan_clustering: 0.052709 seconds\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2017-2020\n",
      "Runtime for dbscan_clustering: 0.106633 seconds\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2018-2021\n",
      "Runtime for dbscan_clustering: 0.118197 seconds\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2019-2022\n",
      "Runtime for dbscan_clustering: 0.100638 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cluster_data_pca_08072025 as cdp\n",
    "from cluster_data_pca_08072025 import run_clustering, normalize_data\n",
    "from DBSCAN import dbscan_clustering\n",
    "import cluster_plotter\n",
    "\n",
    "# --- Style settings ---\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 16,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"axes.titlesize\": 18,\n",
    "    \"legend.fontsize\": 14,\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14\n",
    "})\n",
    "\n",
    "# --- Setup ---\n",
    "plot_dir = \"Images/IAC_plots_followup/DBSCAN_2Dplus_observed\"\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "cluster_plotter.clear_directory(plot_dir)\n",
    "\n",
    "# --- Load observed data ---\n",
    "uncorr_obs_files = {\n",
    "    year: f\"ogs{year}01_12_det.ele_ucorr\" if year != 2002 else f\"ogs{year}08_12_det.ele_ucorr\"\n",
    "    for year in range(2002, 2024) if year != 2018\n",
    "}\n",
    "\n",
    "# --- Define 4-year overlapping ranges ---\n",
    "year_ranges = {\n",
    "    f\"{start}-{start+3}\": np.arange(start, start+4)\n",
    "    for start in range(2002, 2020)  \n",
    "}\n",
    "\n",
    "binned_data = cdp.bin_observed_data(uncorr_obs_files, year_ranges, print_res=False)\n",
    "\n",
    "# --- DBSCAN parameters ---\n",
    "eps_values = [0.11]\n",
    "min_samples_values = [12]\n",
    "\n",
    "# --- Color palette ---\n",
    "extreme_colors = [\n",
    "    \"#3DC53D\", \"#4F4FF3\", '#FFFF00', \"#A148A1\", '#00FFFF',\n",
    "    '#FF8000', '#8000FF', \"#F157A4\", '#00FF80', '#804000', '#000000',\n",
    "    '#808080', '#404040', \"#FF000094\"\n",
    "]\n",
    "\n",
    "# --- Axis labels ---\n",
    "axis_labels = {\n",
    "    \"mean motion\": r\"$n$ [rev/day]\",\n",
    "    \"ecc\": r\"$e$\",\n",
    "    \"inc\": r\"$i$ [°]\",\n",
    "    \"raan\": r\"$\\Omega$ [°]\",\n",
    "    \"arg lat\": r\"$\\lambda$ [°]\",\n",
    "    \"mag\": r\"$m$\"\n",
    "}\n",
    "\n",
    "# --- Run DBSCAN over all year ranges ---\n",
    "for cluster_data, year_range in binned_data:\n",
    "    print(f\"\\nRunning DBSCAN 9D for Year Range: {year_range}\")\n",
    "\n",
    "    # --- Full feature set ---\n",
    "    X_all = np.vstack([\n",
    "        cluster_data.sem_maj,\n",
    "        cluster_data.inc,\n",
    "        cluster_data.raan,\n",
    "        cluster_data.true_lat,\n",
    "        cluster_data.mean_motion,\n",
    "        cluster_data.mag_obj,\n",
    "    ]).T\n",
    "\n",
    "    X_plot = np.vstack([\n",
    "        cluster_data.mean_motion,\n",
    "        cluster_data.inc,\n",
    "        cluster_data.raan,\n",
    "        cluster_data.true_lat,\n",
    "        cluster_data.mag_obj\n",
    "    ]).T\n",
    "\n",
    "    norm_X_all, X_min, X_max = normalize_data(X_all)\n",
    "\n",
    "    for eps in eps_values:\n",
    "        for min_samples in min_samples_values:\n",
    "            # --- Run DBSCAN ---\n",
    "            clustering, duration, n_clusters, pts_per_cluster, _ = run_clustering(\n",
    "                dbscan_clustering, \"DBSCAN\", norm_X_all, X_min, X_max,\n",
    "                eps=eps, min_samples=min_samples\n",
    "            )\n",
    "            labels = clustering.labels\n",
    "\n",
    "            # --- Remap cluster labels ---\n",
    "            unique_labels = sorted(set(labels) - {-1})\n",
    "            label_map = {old: i+1 for i, old in enumerate(unique_labels)}\n",
    "            label_map[-1] = \"Noise\"\n",
    "            mapped_labels = [label_map[l] for l in labels]\n",
    "\n",
    "            # --- Build dataframe ---\n",
    "            df = pd.DataFrame(X_plot, columns=[\n",
    "                \"mean motion\", \"inc\", \"raan\", \"arg lat\", \"mag\"\n",
    "            ])\n",
    "            df['cluster'] = mapped_labels\n",
    "\n",
    "            # --- Pairplot with custom palette ---\n",
    "            palette_map = {i+1: extreme_colors[i % len(extreme_colors)] \n",
    "                           for i in range(len(unique_labels))}\n",
    "            if -1 in labels:\n",
    "                palette_map[\"Noise\"] = \"red\"\n",
    "\n",
    "            pp = sns.pairplot(\n",
    "                df, hue='cluster', diag_kind='kde',\n",
    "                plot_kws={'alpha': 0.8, 's': 15, 'marker': 'o', 'edgecolor': None},\n",
    "                corner=True,\n",
    "                hue_order=[*range(1, len(unique_labels)+1)] + ([\"Noise\"] if -1 in labels else []),\n",
    "                palette=palette_map\n",
    "            )\n",
    "\n",
    "            # --- Set LaTeX labels ---\n",
    "            for ax in pp.axes.flatten():\n",
    "                if ax is not None:\n",
    "                    xlabel = ax.get_xlabel()\n",
    "                    ylabel = ax.get_ylabel()\n",
    "                    if xlabel in axis_labels:\n",
    "                        ax.set_xlabel(axis_labels[xlabel])\n",
    "                    if ylabel in axis_labels:\n",
    "                        ax.set_ylabel(axis_labels[ylabel])\n",
    "\n",
    "            for i, var in enumerate(pp.x_vars):\n",
    "                ax = pp.axes[i, i]\n",
    "                if ax is not None and var in axis_labels:\n",
    "                    ax.set_xlabel(axis_labels[var])\n",
    "                    ax.set_ylabel(axis_labels[var])\n",
    "\n",
    "            # --- Legend formatting ---\n",
    "            for lh in pp._legend.legend_handles:\n",
    "                lh.set_markersize(20)\n",
    "                lh.set_alpha(1.0)\n",
    "                lh.set_markeredgewidth(0)\n",
    "            pp._legend.set_title(\"Cluster\", prop={'size': 17})\n",
    "            for text in pp._legend.get_texts():\n",
    "                text.set_fontsize(17)\n",
    "            pp._legend.set_bbox_to_anchor((0.87, 0.6))\n",
    "            pp._legend.set_frame_on(True)     \n",
    "            pp._legend.get_frame().set_edgecolor(\"grey\")\n",
    "            pp._legend.get_frame().set_linewidth(1.0)\n",
    "\n",
    "            # --- Save pairplot ---\n",
    "            year_label = str(year_range).replace(\"-\", \"_\")\n",
    "            fname = f\"pairplot_{year_label}_eps{eps}_ms{min_samples}_observed.png\"\n",
    "            pp.savefig(os.path.join(plot_dir, fname), bbox_inches=\"tight\", transparent=False)\n",
    "            plt.close(pp.fig)\n",
    "\n",
    "            # --- Semi-major axis distribution ---\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            sns.kdeplot(cluster_data.sem_maj, fill=True, color=\"skyblue\", linewidth=2)\n",
    "            plt.xlabel(r\"$a$ [km]\", fontsize=16)\n",
    "            plt.ylabel(\"Density\", fontsize=16)\n",
    "            plt.title(f\"Semi-Major Axis Distribution {year_range} (eps={eps}, ms={min_samples})\", fontsize=14)\n",
    "            fname_sma = f\"sma_distribution_{year_label}_eps{eps}_ms{min_samples}.png\"\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(plot_dir, fname_sma), transparent=False)\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10b2533",
   "metadata": {},
   "source": [
    "### Observations plots 2D+, DBSCAN, small clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bafe945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fionu\\OneDrive\\Dokumente\\Daten Fiona\\AIUB\\Code\\AIUB-Backup\\clustering\\cluster_data_pca_08072025.py:335: RuntimeWarning: divide by zero encountered in divide\n",
      "  mm = np.sqrt(mu/(sem_maj*1000)**3) #convert semi major from km to m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running DBSCAN 9D for Year Range: 2002-2005\n",
      "Runtime for dbscan_clustering: 0.384275 seconds\n",
      "\n",
      "Removed clusters for eps=0.11, min_samples=12:\n",
      "  Cluster 1: 4647 points\n",
      "  Cluster Noise: 1417 points\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2003-2006\n",
      "Runtime for dbscan_clustering: 0.557396 seconds\n",
      "\n",
      "Removed clusters for eps=0.11, min_samples=12:\n",
      "  Cluster 1: 5377 points\n",
      "  Cluster Noise: 1598 points\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2004-2007\n",
      "Runtime for dbscan_clustering: 0.170432 seconds\n",
      "\n",
      "Removed clusters for eps=0.11, min_samples=12:\n",
      "  Cluster 1: 4791 points\n",
      "  Cluster Noise: 1543 points\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2005-2008\n",
      "Runtime for dbscan_clustering: 0.147256 seconds\n",
      "\n",
      "Removed clusters for eps=0.11, min_samples=12:\n",
      "  Cluster 1: 4461 points\n",
      "  Cluster Noise: 1507 points\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2006-2009\n",
      "Runtime for dbscan_clustering: 0.163638 seconds\n",
      "\n",
      "Removed clusters for eps=0.11, min_samples=12:\n",
      "  Cluster 1: 4299 points\n",
      "  Cluster Noise: 1196 points\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2007-2010\n",
      "Runtime for dbscan_clustering: 0.134355 seconds\n",
      "\n",
      "Removed clusters for eps=0.11, min_samples=12:\n",
      "  Cluster 1: 3335 points\n",
      "  Cluster Noise: 1052 points\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2008-2011\n",
      "Runtime for dbscan_clustering: 0.121061 seconds\n",
      "\n",
      "Removed clusters for eps=0.11, min_samples=12:\n",
      "  Cluster 1: 3158 points\n",
      "  Cluster Noise: 853 points\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2009-2012\n",
      "Runtime for dbscan_clustering: 0.149363 seconds\n",
      "\n",
      "Removed clusters for eps=0.11, min_samples=12:\n",
      "  Cluster 1: 2379 points\n",
      "  Cluster Noise: 780 points\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2010-2013\n",
      "Runtime for dbscan_clustering: 0.067224 seconds\n",
      "\n",
      "Removed clusters for eps=0.11, min_samples=12:\n",
      "  Cluster 1: 1467 points\n",
      "  Cluster Noise: 565 points\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2011-2014\n",
      "Runtime for dbscan_clustering: 0.030372 seconds\n",
      "\n",
      "Removed clusters for eps=0.11, min_samples=12:\n",
      "  Cluster 1: 713 points\n",
      "  Cluster Noise: 540 points\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2012-2015\n",
      "Runtime for dbscan_clustering: 0.023531 seconds\n",
      "\n",
      "Removed clusters for eps=0.11, min_samples=12:\n",
      "  Cluster 1: 328 points\n",
      "  Cluster Noise: 583 points\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2013-2016\n",
      "Runtime for dbscan_clustering: 0.033362 seconds\n",
      "\n",
      "Removed clusters for eps=0.11, min_samples=12:\n",
      "  Cluster 1: 358 points\n",
      "  Cluster Noise: 754 points\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2014-2017\n",
      "Runtime for dbscan_clustering: 0.041912 seconds\n",
      "\n",
      "Removed clusters for eps=0.11, min_samples=12:\n",
      "  Cluster 2: 368 points\n",
      "  Cluster Noise: 862 points\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2015-2018\n",
      "Runtime for dbscan_clustering: 0.042841 seconds\n",
      "\n",
      "Removed clusters for eps=0.11, min_samples=12:\n",
      "  Cluster 2: 294 points\n",
      "  Cluster Noise: 857 points\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2016-2019\n",
      "Runtime for dbscan_clustering: 0.037060 seconds\n",
      "\n",
      "Removed clusters for eps=0.11, min_samples=12:\n",
      "  Cluster 1: 742 points\n",
      "  Cluster Noise: 841 points\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2017-2020\n",
      "Runtime for dbscan_clustering: 0.066571 seconds\n",
      "\n",
      "Removed clusters for eps=0.11, min_samples=12:\n",
      "  Cluster 2: 880 points\n",
      "  Cluster Noise: 987 points\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2018-2021\n",
      "Runtime for dbscan_clustering: 0.098545 seconds\n",
      "\n",
      "Removed clusters for eps=0.11, min_samples=12:\n",
      "  Cluster 1: 1077 points\n",
      "  Cluster Noise: 1035 points\n",
      "\n",
      "Running DBSCAN 9D for Year Range: 2019-2022\n",
      "Runtime for dbscan_clustering: 0.092886 seconds\n",
      "\n",
      "Removed clusters for eps=0.11, min_samples=12:\n",
      "  Cluster 1: 1155 points\n",
      "  Cluster Noise: 1341 points\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cluster_data_pca_08072025 as cdp\n",
    "from cluster_data_pca_08072025 import run_clustering, normalize_data\n",
    "from DBSCAN import dbscan_clustering\n",
    "import cluster_plotter\n",
    "\n",
    "# --- Style settings ---\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 16,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"axes.titlesize\": 18,\n",
    "    \"legend.fontsize\": 14,\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14\n",
    "})\n",
    "\n",
    "# --- Setup ---\n",
    "plot_dir = \"Images/IAC_plots_followup/DBSCAN_2Dplus_observed_smallclusters\"\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "cluster_plotter.clear_directory(plot_dir)\n",
    "\n",
    "# --- Load observed data ---\n",
    "uncorr_obs_files = {\n",
    "    year: f\"ogs{year}01_12_det.ele_ucorr\" if year != 2002 else f\"ogs{year}08_12_det.ele_ucorr\"\n",
    "    for year in range(2002, 2024) if year != 2018\n",
    "}\n",
    "\n",
    "# --- Define 4-year overlapping ranges ---\n",
    "year_ranges = {\n",
    "    f\"{start}-{start+3}\": np.arange(start, start+4)\n",
    "    for start in range(2002, 2020)  \n",
    "}\n",
    "\n",
    "binned_data = cdp.bin_observed_data(uncorr_obs_files, year_ranges, print_res=False)\n",
    "\n",
    "# --- DBSCAN parameters ---\n",
    "eps_values = [0.11]\n",
    "min_samples_values = [12]\n",
    "\n",
    "# --- Extreme contrast color scheme ---\n",
    "extreme_colors = [\n",
    "    \"#3DC53D\", \"#4F4FF3\", '#FFFF00', \"#A148A1\", '#00FFFF',\n",
    "    '#FF8000', '#8000FF', \"#F157A4\", '#00FF80', '#804000', '#000000',\n",
    "    '#808080', '#404040', \"#FF000094\"\n",
    "]\n",
    "\n",
    "# --- Axis labels ---\n",
    "axis_labels = {\n",
    "    \"mean motion\": r\"$n$ [rev/day]\",\n",
    "    \"ecc\": r\"$e$\",\n",
    "    \"inc\": r\"$i$ [°]\",\n",
    "    \"raan\": r\"$\\Omega$ [°]\",\n",
    "    \"arg lat\": r\"$\\lambda$ [°]\",\n",
    "    \"mag\": r\"$m$\"\n",
    "}\n",
    "\n",
    "# --- Run DBSCAN over all ranges ---\n",
    "for cluster_data, year_range in binned_data:\n",
    "    print(f\"\\nRunning DBSCAN 9D for Year Range: {year_range}\")\n",
    "\n",
    "    # --- Full feature set (6D) ---\n",
    "    X_all = np.vstack([\n",
    "        cluster_data.sem_maj,\n",
    "        cluster_data.inc,\n",
    "        cluster_data.raan,\n",
    "        cluster_data.true_lat,\n",
    "        cluster_data.mean_motion,\n",
    "        cluster_data.mag_obj\n",
    "    ]).T\n",
    "\n",
    "    # --- Subset for plotting (5D) ---\n",
    "    X_plot = np.vstack([\n",
    "        cluster_data.mean_motion,\n",
    "        cluster_data.inc,\n",
    "        cluster_data.raan,\n",
    "        cluster_data.true_lat,\n",
    "        cluster_data.mag_obj\n",
    "    ]).T\n",
    "\n",
    "    norm_X_all, X_min, X_max = normalize_data(X_all)\n",
    "\n",
    "    for eps in eps_values:\n",
    "        for min_samples in min_samples_values:\n",
    "            # --- Run clustering ---\n",
    "            clustering, duration, n_clusters, pts_per_cluster, _ = run_clustering(\n",
    "                dbscan_clustering, \"DBSCAN\", norm_X_all, X_min, X_max,\n",
    "                eps=eps, min_samples=min_samples\n",
    "            )\n",
    "            labels = clustering.labels\n",
    "\n",
    "            # --- Remap clusters ---\n",
    "            unique_labels = sorted(set(labels) - {-1})\n",
    "            label_map = {old: i+1 for i, old in enumerate(unique_labels)}\n",
    "            label_map[-1] = \"Noise\"\n",
    "            mapped_labels = [label_map[l] for l in labels]\n",
    "\n",
    "            # --- Build DataFrame ---\n",
    "            df = pd.DataFrame(X_plot, columns=[\n",
    "                \"mean motion\", \"inc\", \"raan\", \"arg lat\", \"mag\"\n",
    "            ])\n",
    "            df['cluster'] = mapped_labels\n",
    "\n",
    "            # --- Remove largest cluster + Noise ---\n",
    "            cluster_sizes = df['cluster'].value_counts()\n",
    "            non_noise_clusters = cluster_sizes.drop(labels=[\"Noise\"], errors=\"ignore\")\n",
    "            clusters_to_remove = []\n",
    "            if not non_noise_clusters.empty:\n",
    "                largest_cluster = non_noise_clusters.idxmax()\n",
    "                clusters_to_remove.append(largest_cluster)\n",
    "            if \"Noise\" in cluster_sizes.index:\n",
    "                clusters_to_remove.append(\"Noise\")\n",
    "\n",
    "            print(f\"\\nRemoved clusters for eps={eps}, min_samples={min_samples}:\")\n",
    "            for cl in clusters_to_remove:\n",
    "                print(f\"  Cluster {cl}: {cluster_sizes[cl]} points\")\n",
    "\n",
    "            df = df[~df['cluster'].isin(clusters_to_remove)]\n",
    "\n",
    "            # --- Original palette mapping ---\n",
    "            original_palette_map = {i+1: extreme_colors[i % len(extreme_colors)] for i in range(len(extreme_colors))}\n",
    "            if \"Noise\" in df['cluster'].unique():\n",
    "                original_palette_map[\"Noise\"] = \"red\"\n",
    "\n",
    "            # --- Keep only remaining clusters in palette ---\n",
    "            remaining_clusters = df['cluster'].unique()\n",
    "            palette_map = {cl: original_palette_map[cl] for cl in remaining_clusters}\n",
    "\n",
    "            # --- Hue order ---\n",
    "            numeric_clusters = sorted([cl for cl in remaining_clusters if isinstance(cl, int)])\n",
    "            hue_order = numeric_clusters\n",
    "            if \"Noise\" in remaining_clusters:\n",
    "                hue_order.append(\"Noise\")\n",
    "\n",
    "            # --- Pairplot ---\n",
    "            pp = sns.pairplot(\n",
    "                df, hue='cluster', diag_kind='kde',\n",
    "                plot_kws={'alpha': 0.8, 's': 15, 'marker': 'o', 'edgecolor': None},\n",
    "                corner=True,\n",
    "                hue_order=hue_order,\n",
    "                palette=palette_map\n",
    "            )\n",
    "\n",
    "            # --- LaTeX labels ---\n",
    "            for ax in pp.axes.flatten():\n",
    "                if ax is not None:\n",
    "                    xlabel = ax.get_xlabel()\n",
    "                    ylabel = ax.get_ylabel()\n",
    "                    if xlabel in axis_labels:\n",
    "                        ax.set_xlabel(axis_labels[xlabel])\n",
    "                    if ylabel in axis_labels:\n",
    "                        ax.set_ylabel(axis_labels[ylabel])\n",
    "\n",
    "            for i, var in enumerate(pp.x_vars):\n",
    "                ax = pp.axes[i, i]\n",
    "                if ax is not None and var in axis_labels:\n",
    "                    ax.set_xlabel(axis_labels[var])\n",
    "                    ax.set_ylabel(axis_labels[var])\n",
    "\n",
    "            # --- Legend formatting ---\n",
    "            for lh in pp._legend.legend_handles:\n",
    "                lh.set_markersize(20)\n",
    "                lh.set_alpha(1.0)\n",
    "                lh.set_markeredgewidth(0)\n",
    "            pp._legend.set_title(\"Cluster\", prop={'size': 17})\n",
    "            for text in pp._legend.get_texts():\n",
    "                text.set_fontsize(17)\n",
    "            pp._legend.set_bbox_to_anchor((0.9, 0.6))\n",
    "            pp._legend.set_frame_on(True)     \n",
    "            pp._legend.get_frame().set_edgecolor(\"grey\")\n",
    "            pp._legend.get_frame().set_linewidth(1.0)\n",
    "\n",
    "            # --- Save ---\n",
    "            year_label = str(year_range).replace(\"-\", \"_\")\n",
    "            fname = f\"pairplot_{year_label}_eps{eps}_ms{min_samples}_observed_smallclusters.png\"\n",
    "            pp.savefig(os.path.join(plot_dir, fname), transparent=False)\n",
    "            plt.close(pp.fig)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
